{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA684 Machine Learning Assignment Spring 2022\n",
    "\n",
    "Dublin City University has teamed up with leading online fashion retailer Zalando to create the 2022 CA684 Machine Learning assignment.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As a customer proposition, Zalando strives for “trustworthy” prices. That is, the company wants to offer competitive prices in each of its dynamic market environments, to alleviate its customers from having to compare prices, and to drive revenue growth. In order to do that for its hundreds of thousands of individual products, Zalando needs to Identify exact product matches across the relevant European competitors. \n",
    "\n",
    "A very similar use case exists at stores like Amazon or Walmart, which allow multiple sellers to offer the same product on their platform: identical products need to be grouped together, even when the names, descriptions, images, etc. are not exactly the same.\n",
    "\n",
    "## Challenge\n",
    "\n",
    "Barcode systems like EAN allow for unique identification of every product. Unfortunately, reliable EAN information is not always available. Zalando uses multi-modal data to solve the problem, relying on images and text. For this challenge, we are asking to make intelligent use of text data (such as product titles, colors and descriptions). As these are not standardized, and often manually written / changed for marketing purposes, matching products is a non-trivial task.\n",
    "\n",
    "This challenge has a direct business impact for a retailer like Zalando. It is also closely related to many other problems, like record deduplication in heterogeneous catalogues, document retrieval, and many more.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Here is some sample code to get you started on the challenge!\n",
    "\n",
    "Happy Hacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import operator\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import urllib\n",
    "from random import choices\n",
    "from itertools import chain\n",
    "# Levenshtein Distance in Python\n",
    "# https://github.com/seatgeek/thefuzz\n",
    "from thefuzz import fuzz, process\n",
    "\n",
    "# Pandas config\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  separating shops \n",
    "zalando_df = offers_training_df[offers_training_df['shop'] == 'zalando'][['offer_id','brand','color','title','description']].reset_index()\n",
    "aboutyou_df = offers_training_df[offers_training_df['shop'] == 'aboutyou'][['offer_id','brand','color','title','description']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102884 entries, 0 to 102883\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   offer_id     102884 non-null  object \n",
      " 1   shop         102884 non-null  object \n",
      " 2   lang         102884 non-null  object \n",
      " 3   brand        102884 non-null  object \n",
      " 4   color        102882 non-null  object \n",
      " 5   title        102884 non-null  object \n",
      " 6   description  102884 non-null  object \n",
      " 7   price        102882 non-null  float64\n",
      " 8   url          102884 non-null  object \n",
      " 9   image_urls   102858 non-null  object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "offers_training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40904 entries, 0 to 40903\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   index            40904 non-null  int64 \n",
      " 1   offer_id         40904 non-null  object\n",
      " 2   brand            40904 non-null  object\n",
      " 3   color            40904 non-null  object\n",
      " 4   title            40904 non-null  object\n",
      " 5   description      40904 non-null  object\n",
      " 6   combo_text       40904 non-null  object\n",
      " 7   norm_combo_text  40904 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "zalando_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61980 entries, 0 to 61979\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   index            61980 non-null  int64 \n",
      " 1   offer_id         61980 non-null  object\n",
      " 2   brand            61980 non-null  object\n",
      " 3   color            61978 non-null  object\n",
      " 4   title            61980 non-null  object\n",
      " 5   description      61980 non-null  object\n",
      " 6   combo_text       61980 non-null  object\n",
      " 7   norm_combo_text  61980 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "aboutyou_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine brand, color, title and decription in one column\n",
    "def combo (df):\n",
    "    return df['brand'] + ' ' + df['color'] + ' ' + df['title'] +' ' + df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column using combo function\n",
    "zalando_df['combo_text'] = combo(zalando_df)\n",
    "zalando_df['combo_text'] = zalando_df['combo_text'].fillna('').apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize combined text\n",
    "def normalizeText(description):\n",
    "    description = re.sub('<.>|<..>', ' ', description.lower())\n",
    "    return re.sub('[^a-z0-9 ]', '', description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for normalized text \n",
    "result_z = []\n",
    "for x in range(len(zalando_df)):\n",
    "    result_z.append(normalizeText(zalando_df['combo_text'][x]))\n",
    "zalando_df['norm_combo_text'] = result_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>combo_text</th>\n",
       "      <th>norm_combo_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>02df5ca3-8adc-48fa-bf42-91b41c3ea5a9</td>\n",
       "      <td>Guess</td>\n",
       "      <td>weiß</td>\n",
       "      <td>JUNIOR REVERSIBLE HOODED LONG Wintermantel</td>\n",
       "      <td>skirt_details Eingrifftaschen | Ziersteine $ n...</td>\n",
       "      <td>Guess weiß JUNIOR REVERSIBLE HOODED LONG Winte...</td>\n",
       "      <td>guess wei junior reversible hooded long winter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                              offer_id  brand color  \\\n",
       "0      5  02df5ca3-8adc-48fa-bf42-91b41c3ea5a9  Guess  weiß   \n",
       "\n",
       "                                        title  \\\n",
       "0  JUNIOR REVERSIBLE HOODED LONG Wintermantel   \n",
       "\n",
       "                                         description  \\\n",
       "0  skirt_details Eingrifftaschen | Ziersteine $ n...   \n",
       "\n",
       "                                          combo_text  \\\n",
       "0  Guess weiß JUNIOR REVERSIBLE HOODED LONG Winte...   \n",
       "\n",
       "                                     norm_combo_text  \n",
       "0  guess wei junior reversible hooded long winter...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zalando_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for aboutyou_df\n",
    "\n",
    "aboutyou_df['combo_text'] = combo(aboutyou_df)\n",
    "aboutyou_df['combo_text'] = aboutyou_df['combo_text'].fillna('').apply(str)\n",
    "\n",
    "result_a = []\n",
    "for x in range(len(aboutyou_df)):\n",
    "    result_a.append(normalizeText(aboutyou_df['combo_text'][x]))\n",
    "aboutyou_df['norm_combo_text'] = result_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>combo_text</th>\n",
       "      <th>norm_combo_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d8e0dba8-98e8-48db-9850-dd30cff374e0</td>\n",
       "      <td>PIECES</td>\n",
       "      <td>hellblau | Blau</td>\n",
       "      <td>Kleid</td>\n",
       "      <td>{\"Material\": [\"Baumwolle\"], \"\\u00c4rmell\\u00e4...</td>\n",
       "      <td>PIECES hellblau | Blau Kleid {\"Material\": [\"Ba...</td>\n",
       "      <td>pieces hellblau  blau kleid material baumwolle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                              offer_id   brand            color  \\\n",
       "0      0  d8e0dba8-98e8-48db-9850-dd30cff374e0  PIECES  hellblau | Blau   \n",
       "\n",
       "   title                                        description  \\\n",
       "0  Kleid  {\"Material\": [\"Baumwolle\"], \"\\u00c4rmell\\u00e4...   \n",
       "\n",
       "                                          combo_text  \\\n",
       "0  PIECES hellblau | Blau Kleid {\"Material\": [\"Ba...   \n",
       "\n",
       "                                     norm_combo_text  \n",
       "0  pieces hellblau  blau kleid material baumwolle...  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aboutyou_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyfuzz import PolyFuzz\n",
    "from polyfuzz.models import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(query, choices, limit=3):\n",
    "    results = process.extract(query, choices, limit=limit)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1= [aboutyou_df.norm_combo_text[0],aboutyou_df.norm_combo_text[1],aboutyou_df.norm_combo_text[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2= [zalando_df.norm_combo_text[10],zalando_df.norm_combo_text[20],zalando_df.norm_combo_text[30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polyfuzz.polyfuzz.PolyFuzz at 0x7ff2d802e340>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PolyFuzz(\"EditDistance\")\n",
    "model.match(list2, list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pieces schwarz pcmaggi midi dress freizeitklei...</td>\n",
       "      <td>pieces hellblau  blau kleid material baumwolle...</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vero moda hellgrn noos strickpullover mainsupp...</td>\n",
       "      <td>pieces hellblau  blau kleid material baumwolle...</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vero moda schwarz vmmollie jacket daunenjacke ...</td>\n",
       "      <td>pieces hellblau  blau kleid material baumwolle...</td>\n",
       "      <td>0.421171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                From  \\\n",
       "0  pieces schwarz pcmaggi midi dress freizeitklei...   \n",
       "1  vero moda hellgrn noos strickpullover mainsupp...   \n",
       "2  vero moda schwarz vmmollie jacket daunenjacke ...   \n",
       "\n",
       "                                                  To  Similarity  \n",
       "0  pieces hellblau  blau kleid material baumwolle...    0.855000  \n",
       "1  pieces hellblau  blau kleid material baumwolle...    0.855000  \n",
       "2  pieces hellblau  blau kleid material baumwolle...    0.421171  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROVIDED CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset will contain files as follows. \n",
    "\n",
    "* Two files containing **offers of products**, for training and testing respectively. An offer is a particular description of a product by an online shop, either Zalando or one of its competitors. They contains the following fields:\n",
    "\n",
    "| Label | Description |\n",
    "|:-----:|:------------|\n",
    "| offer_id | unique identifier for an offer of a product (i.e. a product x shop combination, where we don’t know the product component) |\n",
    "| shop | \"zalando\", \"aboutyou\" |\n",
    "| lang | \"de\" (German) |\n",
    "| brand | e.g. \"Nike\" - note that different `shop`s might have different `brand` nomenclature |\n",
    "| color | e.g. \"blue\" - note that there could be more than one and different `shop`s might have different `brand` nomenclature (\"ocean\", \"light blue\", \"...\") and may have more than one color (ordering matters) |\n",
    "| title | e.g. \"White Nike tennis top\" |\n",
    "| description | a long product description that can may contain material composition, cleaning instructions, etc |\n",
    "| price | price in euro without any discount |\n",
    "| url | url of the product description page |\n",
    "| image_urls | list of product images such as stock photo, with model, lifestyle photo, or close up |\n",
    "\n",
    "* A separate file containing the **matches** in between those offers that describe the same products using the offer id. Note this is only provided for the training offers.\n",
    "\n",
    "| Label | Description |\n",
    "|:-----:|:------------|\n",
    "| zalando | offer_id from “zalando” shop |\n",
    "| aboutyou | offer_id from “aboutyou” shop |\n",
    "| brand | unique identifier for the brand representing the match |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls {offers,matches}_{training,test}.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "It is important to familiarize yourself with the dataset by using measures of centrality (e.g. mean) and statistical dispersion (e.g. variance) and data visualization methods. The following is just some Pandas preprocessing and Matplotlib visualizations to get you started. Feel free to explore the data much further and come up with ideas that might help you in the matching task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers of Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_training_df = pd.read_parquet('offers_training.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_test_df = pd.read_parquet('offers_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_training_df = pd.read_parquet('matches_training.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_training_df[offers_training_df['offer_id'] == 'b33f55d6-0149-4063-8b63-3eeae63562a2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_training_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'Number of products in training: {len(offers_training_df):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list(offers_training_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_training_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_training_df['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.value_counts(offers_training_df['shop'], sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure, ax = plt.subplots(figsize=(15, 5))\n",
    "pd.value_counts(\n",
    "    offers_training_df[\n",
    "        offers_training_df['title'].str.lower().str.contains(\"t-shirt\", na=False)\n",
    "    ]['shop'], \n",
    "    sort=True, ascending=False).plot.barh(color='darkcyan')\n",
    "plt.title('T-Shirt Offers of Products per Shop')\n",
    "xlabels = [f'{x:,}' for x in range(0, 3500, 500)]\n",
    "plt.xticks(range(0, 3500, 500), xlabels)\n",
    "plt.xlabel('Number of products')\n",
    "plt.setp(ax.get_xticklabels()[0], visible=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure, ax = plt.subplots(figsize=(15, 5))\n",
    "plt.title('Histogram of Prices (Products under 300€)')\n",
    "offers_training_df[\n",
    "    offers_training_df['price'] < 300\n",
    "]['price'].plot.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brands_training = offers_training_df['brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brands_training[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'Number of unique brands in training: {len(brands_training):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_test_df = pd.read_parquet('offers_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'Number of products in test: {len(offers_test_df):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brands_test = offers_test_df['brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'Number of unique brands in test: {len(brands_test):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that Brands in training and test are different!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection between brands in training and test\n",
    "f'Number of brands in train and test: {sum(np.in1d(brands_training, brands_test, assume_unique=True)):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches\n",
    "\n",
    "**Note** that matches for the offers in testing are hidden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_training_df = pd.read_parquet('matches_training.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'Number of groundtruth matches: {len(matches_training_df):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matches_training_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_offer(products, match, shop):\n",
    "    return products[\n",
    "        products['offer_id'] == match[shop]\n",
    "    ].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f\"Number of unique brands in training matches: {len(offers_training_df['brand'].unique()):,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_images(product):\n",
    "    \n",
    "    # Data\n",
    "    images = product['image_urls']\n",
    "    \n",
    "    # Plot it!\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(images), figsize=(12, 4), dpi=100)\n",
    "    \n",
    "    if len(images) > 1:     \n",
    "        axes = axes.flatten()\n",
    "        for i, axis in enumerate(axes):\n",
    "            url = images[i]\n",
    "            image = np.array(Image.open(urllib.request.urlopen(url)))\n",
    "            axis.imshow(image)\n",
    "            axis.axis('off')\n",
    "    else:\n",
    "        url = images[0]\n",
    "        image = np.array(Image.open(urllib.request.urlopen(url)))\n",
    "        axes.imshow(image)\n",
    "        axes.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index = 9209 # particular index\n",
    "product = get_offer(offers_training_df, matches_training_df.iloc[index], 'zalando')\n",
    "product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Zalando')\n",
    "plot_images(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product = get_offer(offers_training_df, matches_training_df.iloc[index], 'aboutyou')\n",
    "product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('AboutYou')\n",
    "plot_images(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching\n",
    "\n",
    "The task is to predict the matches for the offers in testing making use of the offers in training and the corresponding groundtruth matches. Feel free to use any Machine Learning library you like such as Pytorch, TensorFlow or scikit-learn. An idea is to split the training data into train and validation to measure the generalizability of your approach. The following is just a slow and dummy algorithm to get you started just looking at a few brands.\n",
    "\n",
    "**Note** that it might help map brands first between Zalando and AboutYou.\n",
    "\n",
    "Get creative!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_shops_for_brand(offers, brands):\n",
    "    \"\"\" Get mapping for brands in between the two shops \"\"\"\n",
    "    \n",
    "    mapping = {}\n",
    "    for brand in brands:\n",
    "        shops = offers[offers[\"brand\"] == brand][\"shop\"].unique()\n",
    "        for shop in shops:\n",
    "            mapping.setdefault(shop, [])\n",
    "            mapping[shop].append(brand)\n",
    "        print(f'Brand: \"{brand}\" is in {\", \".join(shops)}')\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_offers_by_shop(offers, mapping):\n",
    "    \"\"\" Get offers per shop \"\"\"\n",
    "    \n",
    "    offers_zal = offers[\n",
    "        (offers['shop'] == 'zalando') & \n",
    "        (offers['brand'].isin(mapping['zalando']))\n",
    "    ]\n",
    "    offers_comp = offers[\n",
    "        (offers['shop'] == 'aboutyou') &\n",
    "        (offers['brand'].isin(mapping['aboutyou']))\n",
    "    ]\n",
    "    return offers_zal, offers_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_features(offers):\n",
    "    \"\"\" Extract some text features using title and color \"\"\"\n",
    "    \n",
    "    offers['text'] = offers[\n",
    "        ['title','color']\n",
    "    ].apply(lambda x : f\"{x[0]} {x[1].split('|')[0]}\", axis=1)\n",
    "    \n",
    "    return offers[['offer_id', 'text']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def dummy_matcher(zal_offers, comp_offers, brand_block_index):\n",
    "    \"\"\"\n",
    "    Slow and dummy matcher that matches each Zalando offer to an AboutYou offer \n",
    "    Note: there is no need to match all offers as not all of them can be matched\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get text from offers\n",
    "    comp_text = comp_offers[:, 1]\n",
    "    choices_dict = {idx: el for idx, el in enumerate(comp_text)}\n",
    "    \n",
    "    predicted_matches = []\n",
    "\n",
    "    # For each zalando offer\n",
    "    for zal_offer_id, zal_text in zal_offers:\n",
    "        \n",
    "        # Extract the best match using TheFuzz's package\n",
    "        title, score, index = process.extractOne(zal_text, choices_dict) \n",
    "        comp_offer_id = comp_offers[index][0]\n",
    "\n",
    "        # Add predicted match\n",
    "        predicted_matches.append(\n",
    "            {\n",
    "                'zalando': zal_offer_id,\n",
    "                'aboutyou': comp_offer_id,\n",
    "                'brand': brand_block_index\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(predicted_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_brand_predictions(brand_pattern, brand_unique_index):\n",
    "    \"\"\" \n",
    "    Custom pipeline to get the brand mapping, offers per shop, extract the features and generate predictions\n",
    "    \"\"\"\n",
    "\n",
    "    list_brands = [\n",
    "        brand\n",
    "        for brand in brands_training\n",
    "        if brand_pattern in brand.lower()\n",
    "    ]\n",
    "\n",
    "    # Get brand mapping\n",
    "    brand_mapping = get_shops_for_brand(offers_training_df, list_brands)\n",
    "    print(f'Mapping: {brand_mapping}')\n",
    "\n",
    "    # Get offers\n",
    "    brand_offers_zal, brand_offers_comp = get_offers_by_shop(offers_training_df, brand_mapping)\n",
    "    \n",
    "    print(f'Number of \"{brand_pattern}\" products: {len(brand_offers_zal) + len(brand_offers_comp):,} (' + \\\n",
    "          f'Zalando: {len(brand_offers_zal):,} ' + \\\n",
    "          f'and AboutYou: {len(brand_offers_comp):,})')\n",
    "\n",
    "    # Get features\n",
    "    brand_offers_zal_features = get_features(brand_offers_zal)\n",
    "    brand_offers_comp_features = get_features(brand_offers_comp)\n",
    "\n",
    "    # Match!\n",
    "    predictions = dummy_matcher(\n",
    "        brand_offers_zal_features, \n",
    "        brand_offers_comp_features, \n",
    "        brand_unique_index\n",
    "    )\n",
    "    \n",
    "    print(f'Number of predicted matches for \"{brand_pattern}\": {len(predictions):,}')\n",
    "    \n",
    "    return brand_offers_zal, brand_offers_comp, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quiksilver_offers_zal, quiksilver_offers_comp, quiksilver_predicted_matches = get_brand_predictions('quiksilver', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "burberry_offers_zal, burberry_offers_comp, burberry_predicted_matches = get_brand_predictions('burberry', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veja_offers_zal, veja_offers_comp, veja_predicted_matches = get_brand_predictions('veja', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we just learned some mapping between the offers and the matches, we can evaluate the performance of our matching algorithm. In a qualitative way, we can explore the matches using the actual images as we can quickly figure out whether that is actually a match or not. In a quantitative manner, we can measure its performance leveraging F1, precision and recall metrics after calculating the confusion matrix between actual matches and the predicted ones. \n",
    "\n",
    "The goal of the assignment is to maximize F1 overall!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def explore_match(match):\n",
    "    \"\"\" Explore a match with the offers' images \"\"\"\n",
    "    \n",
    "    # get offer ids\n",
    "    zal_offer_id = match['zalando']\n",
    "    comp_offer_id = match['aboutyou']\n",
    "    \n",
    "    # get offers\n",
    "    zalando_offer = offers_training_df[offers_training_df['offer_id'] == zal_offer_id].iloc[0]\n",
    "    comp_offer = offers_training_df[offers_training_df['offer_id'] == comp_offer_id].iloc[0]\n",
    "    \n",
    "    # show images and text\n",
    "    print(f\"Zalando: {zalando_offer['title']} {zalando_offer['color']}\")\n",
    "    plot_images(zalando_offer)\n",
    "    print(f\"AboutYou: {comp_offer['title']} {zalando_offer['color']}\")\n",
    "    plot_images(comp_offer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_true_matches_brand(zal_offers):\n",
    "    \"\"\" Get true matches based on their brand block \"\"\"\n",
    "    \n",
    "    # get brand block / mapping index from the training matches\n",
    "    indexes = zal_offers.merge(\n",
    "        matches_training_df,\n",
    "        left_on='offer_id',\n",
    "        right_on='zalando',\n",
    "        suffixes=['offer', 'match']\n",
    "    )['brandmatch'].unique()\n",
    "    \n",
    "    return matches_training_df[matches_training_df['brand'].isin(indexes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_metrics(true_matches, predicted_matches, offers_comp):\n",
    "    \"\"\" Calculate performance metrics \"\"\"\n",
    "    \n",
    "    # True Positives\n",
    "    TP = len(\n",
    "        true_matches.merge(\n",
    "            predicted_matches, \n",
    "            on=['zalando', 'aboutyou'], \n",
    "            how='inner', \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # False Negatives\n",
    "    FN = len(true_matches) - TP\n",
    "    \n",
    "    # Actual Positives\n",
    "    positives = len(true_matches)\n",
    "    assert positives == TP + FN\n",
    "    \n",
    "    # Actual Negatives (with respect to the competitor)\n",
    "    negatives = len(offers_comp) - positives\n",
    "    \n",
    "    # Actual negative values (with respect to the competitor)\n",
    "    offers_comp_with_matches = offers_comp.merge(\n",
    "        true_matches, \n",
    "        left_on='offer_id',\n",
    "        right_on='aboutyou',\n",
    "        how='outer',\n",
    "        indicator=True\n",
    "    )\n",
    "    negative_values = offers_comp_with_matches[\n",
    "        offers_comp_with_matches['_merge'] == 'left_only'\n",
    "    ]['offer_id'].unique()\n",
    "    \n",
    "    assert negatives == len(negative_values)\n",
    "    \n",
    "    # Competitor predictions\n",
    "    comp_preds = predicted_matches['aboutyou'].unique()\n",
    "    \n",
    "    # False Negatives (with respect to the competitor)\n",
    "    FP = len(np.intersect1d(negative_values, comp_preds))\n",
    "    \n",
    "    # True Negatives\n",
    "    TN = negatives - FP\n",
    "    \n",
    "    # Precision, Recall and F1 metrics\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 0\n",
    "    if precision + recall > 0:\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    metrics = dict(\n",
    "        TP=TP,\n",
    "        FN=FN,\n",
    "        FP=FP,\n",
    "        TN=TN,\n",
    "        positives=positives,\n",
    "        negatives=negatives,\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        F1=F1,\n",
    "    )\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_brand_metrics(brand_offers_zal, brand_offers_comp, brand_predicted_matches):\n",
    "\n",
    "    # Get groundtruth\n",
    "    brand_true_matches = get_true_matches_brand(brand_offers_zal)\n",
    "    \n",
    "    print(f'Number of true matches: {len(brand_true_matches):,}')\n",
    "\n",
    "    # Get metrics\n",
    "    brand_metrics = get_metrics(brand_true_matches, brand_predicted_matches, brand_offers_comp)\n",
    "    \n",
    "    return brand_true_matches, brand_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore a particular predicted match\n",
    "predicted_match = quiksilver_predicted_matches.iloc[27]\n",
    "explore_match(predicted_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a correct match!\n",
    "\n",
    "Let's see some details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_offer(offers_training_df, predicted_match, 'zalando')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_offer(offers_training_df, predicted_match, 'aboutyou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundtruth match (note: there is a true match for this particular offer)\n",
    "true_match = matches_training_df[\n",
    "    matches_training_df['zalando'] == quiksilver_predicted_matches.iloc[27]['zalando']\n",
    "].iloc[0]\n",
    "explore_match(true_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quiksilver_true_matches, quiksilver_metrics = get_brand_metrics(\n",
    "    quiksilver_offers_zal, quiksilver_offers_comp, quiksilver_predicted_matches)\n",
    "quiksilver_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of these results!\n",
    "\n",
    "For Quiksilver, we figured out 10 matches, true positives, out of the 98 actual matches (positives) by just using the title and color of the offers. Hence, 88 were false negatives, we failed to predict them as matches. In terms of the actual negatives, there were 243 offers in AboutYou that did not have a corresponding match. We predicted 54 of those to have a match but in reality they did not any, those are our false positives. The rest are correct true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "burberry_true_matches, burberry_metrics = get_brand_metrics(\n",
    "    burberry_offers_zal, burberry_offers_comp, burberry_predicted_matches)\n",
    "burberry_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veja_true_matches, veja_metrics = get_brand_metrics(veja_offers_zal, veja_offers_comp, veja_predicted_matches)\n",
    "veja_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure our metrics over all the offers in the groundtruth. **Note** that there is no need to perform predictions per brand block, it is just an approach used in this notebook to showcase matches and not matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offers_zal = offers_training_df[offers_training_df['shop'] == 'zalando']\n",
    "offers_comp = offers_training_df[offers_training_df['shop'] == 'aboutyou']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted_matches = pd.concat([\n",
    "    quiksilver_predicted_matches,\n",
    "    burberry_predicted_matches,\n",
    "    veja_predicted_matches\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_metrics(matches_training_df, predicted_matches, offers_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the assignment is to maximize that F1 over all the test offers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Prepare a submission for matching the test offers between Zalando and AboutYou. The following example makes predictions for just a few brand blocks that are identified from the test offers. The objective is to make predictions for all test offers. Remember not all of them will have matches!\n",
    "\n",
    "Happy Hacking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dkny_brands = [\n",
    "    brand\n",
    "    for brand in brands_test\n",
    "    if 'dkny' in brand.lower()\n",
    "]\n",
    "\n",
    "dkny_brand_mapping = get_shops_for_brand(offers_test_df, dkny_brands)\n",
    "dkny_brand_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gant_brands = [\n",
    "    brand\n",
    "    for brand in brands_test\n",
    "    if 'gant' in brand.lower()\n",
    "]\n",
    "\n",
    "gant_brand_mapping = get_shops_for_brand(offers_test_df, gant_brands)\n",
    "gant_brand_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brand mappings for brands in test offers\n",
    "test_mapping = [\n",
    "    dkny_brand_mapping,\n",
    "    gant_brand_mapping\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_test_predictions(mapping):\n",
    "    \"\"\" Predicts brands per block for the test set \"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for brand_index, brand_mapping in enumerate(mapping):\n",
    "\n",
    "        print(f'Predicting for block {\", \".join(list(chain.from_iterable(brand_mapping.values())))}...')\n",
    "\n",
    "        # Get offers\n",
    "        brand_offers_zal, brand_offers_comp = get_offers_by_shop(offers_test_df, brand_mapping)\n",
    "        print(f'Number of offers: {len(brand_offers_zal) + len(brand_offers_comp):,}')\n",
    "\n",
    "        # Get features\n",
    "        brand_offers_zal_features = get_features(brand_offers_zal)\n",
    "        brand_offers_comp_features = get_features(brand_offers_comp)\n",
    "\n",
    "        # Match!\n",
    "        brand_pred_matches = dummy_matcher(\n",
    "            brand_offers_zal_features, \n",
    "            brand_offers_comp_features, \n",
    "            brand_index\n",
    "        )\n",
    "        print(f'Number of matches: {len(brand_pred_matches):,}')\n",
    "\n",
    "        # Add the predictions\n",
    "        predictions.append(brand_pred_matches)\n",
    "\n",
    "    return pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions_df = get_test_predictions(test_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions_df.to_parquet('matches_test_predicted.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
